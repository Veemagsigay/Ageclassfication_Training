{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8190477f",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "COCONUT AGE CLASSFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d018ca6f",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7efce4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c:\\Users\\Mary' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.12.0.88)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from opencv-python) (2.2.2)\n",
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mary vee\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mary vee\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mary vee\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (6.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mary vee\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mary vee\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mary vee\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement scikoit-learn (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for scikoit-learn\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Sudo is disabled on this machine. To enable it, go to the \u001b]8;;ms-settings:developers\u001b\\Developer Settings page\u001b]8;;\u001b\\ in the Settings app\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0  4734    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "curl: (23) Failure writing output to destination, passed 4734 returned 0\n",
      "'rclone' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'rclone' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install opencv-python\n",
    "!\"{sys.executable}\" -m pip install opencv-python\n",
    "%pip install tensorflow\n",
    "%pip install pandas\n",
    "%pip install scikoit-learn\n",
    "!curl https://rclone.org/install.sh | sudo bash\n",
    "!rclone config\n",
    "!rclone ls gdrive:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a91cb",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41467356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The folder 'G:\\My Drive\\THESIS JOURNEY\\Coconut Dataset' does not exist. Please check the path.\n"
     ]
    }
   ],
   "source": [
    "# folder path inside Drive\n",
    "dataset_dir = r\"G:\\My Drive\\THESIS JOURNEY\\Coconut Dataset\"\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# IMAGE PREPROCESSING\n",
    "#-----------------------------------\n",
    "\n",
    "img_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),   # Flipping\n",
    "    layers.RandomRotation(0.2),                     # Rotation\n",
    "    layers.RandomZoom(0.2),                         # Zooming\n",
    "    layers.RandomContrast(0.2),                     # Contrast\n",
    "    layers.RandomTranslation(0.1, 0.1),             # Shifting\n",
    "    layers.Resizing(224, 224),                      # Resize to MobileNet input size\n",
    "    layers.Rescaling(1./255, offset=-1),            # Normalization to [-1,1]\n",
    "    layers.CenterCrop(224, 224)\n",
    "])\n",
    "\n",
    "max_count = max(class_counts.values())\n",
    "print(f\"Max sample among classes: {max_count}\")  \n",
    "\n",
    "# Create a balanced dataset by duplicating images in underrepresented classes\n",
    "for class_name, count in class_count.item():\n",
    "    class_path = os.path.join(dataset_dir, class_name)\n",
    "    balanced_class_path = os.path.join(dataset_dir, f\"balanced_{class_name}\")\n",
    "    os.makedirs(balanced_class_path, exist_ok=True)       \n",
    "\n",
    "# List all images in the class directory\n",
    "pic = [\n",
    "    os.path.join(class_path, img) for img in os.listdir(class_path)\n",
    "    if img.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))\n",
    "]\n",
    "\n",
    "# Copy all the original images first\n",
    "for img in pic:\n",
    "    shutil.copy(img, balanced_class_path)\n",
    "\n",
    "# If the class has fewer images than the max count, duplicate images\n",
    "# Augment it until it will become balanced\n",
    "while len(os.listdir(balanced_class_path)) < max_count:\n",
    "    img_to_aug = random.choice(pic)\n",
    "    # You can add augmentation code here if needed\n",
    "    shutil.copy(img_to_aug, balanced_class_path)\n",
    "        \n",
    "    # Load image\n",
    "    pil_img = Image.open(img_to_aug).convert(\"RGB\").resize((224, 224))\n",
    "    arr = np.array(pil_img) / 255.0\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    \n",
    "    # Applying Augmentation\n",
    "    aug_img = augment(arr, training=True).nmpy()[0]\n",
    "    aug_img = (aug_img * 255).astype(np.uint8)\n",
    "    \n",
    "    # Save augmented image\n",
    "    aug_img_name = f\"aug_{(os.listdir(balanced_class_path))}_{os.path.basename(img_to_aug)}\"\n",
    "    Image.fromarray(aug_img).save(os.path.join(balanced_class_path, aug_img_name))\n",
    "    \n",
    "# Combine all balanced class directories into a single balanced dataset directory\n",
    "balanced_dataset_dir = os.path.join(os.path.dirname(dataset_dir), \"balanced_dataset\")\n",
    "os.makedirs(balanced_dataset_dir, exist_ok=True)\n",
    "for class_name in class_count.keys():\n",
    "    src = os.path.join(dataset_dir, f\"balanced_{class_name}\")\n",
    "    dst = os.path.join(balanced_dataset_dir, class_name)\n",
    "    shutil.move(src, dst)\n",
    "\n",
    "print(\"Balanced dataset created at:\", balanced_dataset_dir)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be4d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age_formula  actual_age  final_age\n",
      "0      20.233333          18  44.217924\n",
      "1      20.233333          18  44.217924\n",
      "2      20.233333          18  44.217924\n",
      "3      19.061538          18  41.045622\n",
      "4      19.061538          18  41.045622\n",
      "..           ...         ...        ...\n",
      "195    25.594595          49  58.732018\n",
      "196    25.594595          49  58.732018\n",
      "197    22.720930          49  50.952387\n",
      "198    22.720930          49  50.952387\n",
      "199    22.720930          49  50.952387\n",
      "\n",
      "[200 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mary Vee\\AppData\\Local\\Temp\\ipykernel_13884\\88821929.py:27: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  a = float(reg.coef_[0])\n",
      "C:\\Users\\Mary Vee\\AppData\\Local\\Temp\\ipykernel_13884\\88821929.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  b = float(reg.intercept_)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the numerical dataset\n",
    "df = pd.read_csv('Numerical_Datasets.csv', header=1) \n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# NUMERICAL PREPROCESSING\n",
    "#-----------------------------------\n",
    "\n",
    "# Step 1: Ensure numeric data\n",
    "for c in [\"HeightTrunk\", \"11leafscars\", \"Year\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# Step 2: Applying the PCA Formula: Age = TrunkHeight / L11 + 5\n",
    "df[\"age_formula\"] = df[\"HeightTrunk\"] / df[\"11leafscars\"] + 5\n",
    "\n",
    "# Step 3: Min-Max Scaling\n",
    "if \"Year\" in df.columns and df[\"Year\"].notna().any():\n",
    "    df[\"actual_age\"] = 2025 - df[\"Year\"]\n",
    "\n",
    "    # Step 4: Calibrate the formula using linear regression\n",
    "    mask = df[\"actual_age\"].notna() & np.isfinite(df[\"actual_age\"])\n",
    "    x = df.loc[mask, [\"age_formula\"]]\n",
    "    y = df.loc[mask, [\"actual_age\"]]\n",
    "\n",
    "    # Step 5: Fit linear regression model\n",
    "    reg = LinearRegression().fit(x, y)\n",
    "    a = float(reg.coef_[0])\n",
    "    b = float(reg.intercept_)\n",
    "else:\n",
    "    # Fallback if no year column\n",
    "    a, b = 1.0, 0.0    \n",
    "\n",
    "# Step 6: Apply calibrated formula\n",
    "df[\"final_age\"] = a * df[\"age_formula\"] + b\n",
    "\n",
    "# Steo 7: Clip negative aged or unrealistic ages\n",
    "df[\"final_age\"] = df[\"final_age\"].clip(lower=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 5: Show the results\n",
    "#print(\"Calibrated a, b:\", a, b)\n",
    "print(df[[\"age_formula\",\"actual_age\",\"final_age\"]].head(200))\n",
    "#print(df[['HeightTrunk','11leafscars']].head(10))\n",
    "#print(df[['HeightTrunk','11leafscars']].describe())\n",
    "#print(df[['age_formula']].head(10))\n",
    "#print(df[['final_age']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f363a89",
   "metadata": {},
   "source": [
    "## TRAINING THE MODEL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3090d1d5",
   "metadata": {},
   "source": [
    "### CNN-MOBILE NET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe21dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26eb9b3c",
   "metadata": {},
   "source": [
    "### SVM CLASSIFICATION \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873906e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
